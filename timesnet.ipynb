{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789c6d50-3faa-45de-bdcd-6697643b6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1660 Ti\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #disable CUDA by setting CUDA_VISIBLE_DEVICES to an empty string \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b77ff09-17e6-429c-bd11-9c379c891c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp():\n",
    "    if args.is_training:\n",
    "        for ii in range(args.itr):\n",
    "            # setting record of experiments\n",
    "            exp = Exp(args)  # set experiments\n",
    "            setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "                args.task_name,\n",
    "                args.model_id,\n",
    "                args.model,\n",
    "                args.data,\n",
    "                args.features,\n",
    "                args.seq_len,\n",
    "                args.label_len,\n",
    "                args.pred_len,\n",
    "                args.d_model,\n",
    "                args.n_heads,\n",
    "                args.e_layers,\n",
    "                args.d_layers,\n",
    "                args.d_ff,\n",
    "                args.factor,\n",
    "                args.embed,\n",
    "                args.distil,\n",
    "                args.des, ii)\n",
    "    \n",
    "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "            exp.train(setting)\n",
    "    \n",
    "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "            exp.test(setting)\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8dc673d-6d5c-41a3-8423-cafe5c366477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'task_name': 'classification', 'is_training': 1, 'model_id': 'test', 'model': 'TimesNet', 'data': 'UEA', 'root_path': './dataset/commodity/coffee/', 'data_path': 'coffee', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './checkpoints/', 'seq_len': 96, 'label_len': 14, 'pred_len': 96, 'seasonal_patterns': 'Monthly', 'inverse': False, 'mask_rate': 0.25, 'anomaly_ratio': 0.25, 'top_k': 2, 'num_kernels': 4, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 32, 'd_ff': 16, 'moving_avg': 25, 'factor': 1, 'distil': True, 'dropout': 0.05, 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'channel_independence': 0, 'num_workers': 10, 'itr': 1, 'train_epochs': 100, 'batch_size': 8, 'patience': 3, 'learning_rate': 0.0005, 'des': 'test', 'loss': 'MSE', 'lradj': 'type1', 'use_amp': False, 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': True, 'devices': '0,1,2,3'}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from exp.exp_classification import Exp_Classification\n",
    "import random\n",
    "import numpy as np\n",
    "from utils.tools import dotdict\n",
    "\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='TimesNet')\n",
    "\n",
    "# basic config\n",
    "parser.add_argument('--task_name', type=str, required=True, default='long_term_forecast',\n",
    "                    help='task name, options:[long_term_forecast, short_term_forecast, imputation, classification, anomaly_detection]')\n",
    "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
    "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, required=True, default='Autoformer',\n",
    "                    help='model name, options: [Autoformer, Transformer, TimesNet]')\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/ETT/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')\n",
    "parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='subset for M4')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "\n",
    "# inputation task\n",
    "parser.add_argument('--mask_rate', type=float, default=0.25, help='mask ratio')\n",
    "\n",
    "# anomaly detection task\n",
    "parser.add_argument('--anomaly_ratio', type=float, default=0.25, help='prior anomaly ratio (%)')\n",
    "\n",
    "# model define\n",
    "parser.add_argument('--top_k', type=int, default=5, help='for TimesBlock')\n",
    "parser.add_argument('--num_kernels', type=int, default=6, help='for Inception')\n",
    "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')\n",
    "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')\n",
    "parser.add_argument('--c_out', type=int, default=7, help='output size')\n",
    "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')\n",
    "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')\n",
    "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')\n",
    "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')\n",
    "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')\n",
    "parser.add_argument('--factor', type=int, default=1, help='attn factor')\n",
    "parser.add_argument('--distil', action='store_false',\n",
    "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
    "                    default=True)\n",
    "parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n",
    "parser.add_argument('--embed', type=str, default='timeF',\n",
    "                    help='time features encoding, options:[timeF, fixed, learned]')\n",
    "parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in ecoder')\n",
    "parser.add_argument('--channel_independence', type=int, default=0,\n",
    "                    help='1: channel dependence 0: channel independence for FreTS model')\n",
    "# optimization\n",
    "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "parser.add_argument('--itr', type=int, default=1, help='experiments times')\n",
    "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
    "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')\n",
    "parser.add_argument('--des', type=str, default='test', help='exp description')\n",
    "parser.add_argument('--loss', type=str, default='MSE', help='loss function')\n",
    "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')\n",
    "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)\n",
    "\n",
    "# GPU\n",
    "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "\n",
    "# de-stationary projector params\n",
    "parser.add_argument('--p_hidden_dims', type=int, nargs='+', default=[128, 128],\n",
    "                    help='hidden layer dimensions of projector (List)')\n",
    "parser.add_argument('--p_hidden_layers', type=int, default=2, help='number of hidden layers in projector')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = dotdict()\n",
    "\n",
    "# basic config\n",
    "args.task_name= 'classification'\n",
    "args.is_training= 1\n",
    "args.model_id= 'test'\n",
    "args.model= 'TimesNet'\n",
    "\n",
    "# data loader\n",
    "args.data = 'UEA'\n",
    "args.root_path = './dataset/commodity/coffee/'\n",
    "args.data_path ='coffee' \n",
    "args.features = 'M'\n",
    "args.target = 'OT'\n",
    "args.freq = 'h'\n",
    "args.checkpoints = './checkpoints/'\n",
    "\n",
    "# forecasting task\n",
    "args.seq_len= 96\n",
    "args.label_len= 14\n",
    "args.pred_len= 96\n",
    "args.seasonal_patterns= 'Monthly'\n",
    "args.inverse= False\n",
    "\n",
    "# imputation task\n",
    "args.mask_rate= 0.25\n",
    "\n",
    "# anomaly detection task\n",
    "args.anomaly_ratio= 0.25\n",
    "\n",
    "# model define\n",
    "args.top_k= 2\n",
    "args.num_kernels= 4\n",
    "args.enc_in= 7\n",
    "args.dec_in= 7\n",
    "args.c_out= 7\n",
    "args.d_model= 512 # changed 512\n",
    "args.n_heads= 8\n",
    "args.e_layers= 2\n",
    "args.d_layers= 32\n",
    "args.d_ff= 16 # changed from 2048\n",
    "args.moving_avg= 25\n",
    "args.factor= 1 # changed from 1 \n",
    "args.distil= True\n",
    "args.dropout= 0.05\n",
    "args.embed= 'timeF'\n",
    "args.activation= 'gelu'\n",
    "args.output_attention= False\n",
    "args.channel_independence= 0\n",
    "\n",
    "# optimization\n",
    "args.num_workers= 10\n",
    "args.itr= 1\n",
    "args.train_epochs= 100\n",
    "args.batch_size= 8\n",
    "args.patience= 3\n",
    "args.learning_rate= 0.0005\n",
    "args.des= 'test'\n",
    "args.loss= 'MSE'\n",
    "args.lradj= 'type1'\n",
    "args.use_amp= False\n",
    "\n",
    "# GPU\n",
    "args.use_gpu= True\n",
    "args.gpu= 0\n",
    "args.use_multi_gpu= True\n",
    "args.devices= '0,1,2,3'\n",
    "\n",
    "# de-stationary projector param\n",
    "p_hidden_dims= [128, 128]\n",
    "p_hidden_layers= 2\n",
    "\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)\n",
    "\n",
    "if args.task_name == 'long_term_forecast':\n",
    "    Exp = Exp_Long_Term_Forecast\n",
    "elif args.task_name == 'short_term_forecast':\n",
    "    Exp = Exp_Short_Term_Forecast\n",
    "elif args.task_name == 'imputation':\n",
    "    Exp = Exp_Imputation\n",
    "elif args.task_name == 'anomaly_detection':\n",
    "    Exp = Exp_Anomaly_Detection\n",
    "elif args.task_name == 'classification':\n",
    "    Exp = Exp_Classification\n",
    "else:\n",
    "    Exp = Exp_Long_Term_Forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e6656-791c-4160-a136-1c7a482251ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "TRAIN\n",
      "2010\n",
      "TEST\n",
      "503\n",
      ">>>>>>>start training : classification_test_TimesNet_UEA_ftM_sl4_ll14_pl0_dm512_nh8_el2_dl32_df16_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "TRAIN\n",
      "2010\n",
      "TEST\n",
      "503\n",
      "TEST\n",
      "503\n",
      "\titers: 100, epoch: 1 | loss: 0.8623445\n",
      "\tspeed: 0.4053s/iter; left time: 10172.8312s\n",
      "\titers: 200, epoch: 1 | loss: 0.9460554\n",
      "\tspeed: 0.0193s/iter; left time: 483.6492s\n",
      "Epoch: 1 cost time: 44.913442611694336\n",
      "Epoch: 1, Steps: 252 | Train Loss: 0.770 Vali Loss: 0.711 Vali Acc: 0.491 Test Loss: 0.711 Test Acc: 0.491\n",
      "Validation loss decreased (inf --> -0.491054).  Saving model ...\n",
      "\titers: 100, epoch: 2 | loss: 0.5215203\n",
      "\tspeed: 0.6308s/iter; left time: 15675.5331s\n",
      "\titers: 200, epoch: 2 | loss: 0.6149132\n",
      "\tspeed: 0.0188s/iter; left time: 465.2888s\n",
      "Epoch: 2 cost time: 41.04094958305359\n",
      "Epoch: 2, Steps: 252 | Train Loss: 0.763 Vali Loss: 0.702 Vali Acc: 0.477 Test Loss: 0.702 Test Acc: 0.477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "\titers: 100, epoch: 3 | loss: 0.6710754\n",
      "\tspeed: 0.6240s/iter; left time: 15348.4175s\n",
      "\titers: 200, epoch: 3 | loss: 0.7773721\n",
      "\tspeed: 0.0185s/iter; left time: 454.2723s\n",
      "Epoch: 3 cost time: 40.1637499332428\n",
      "Epoch: 3, Steps: 252 | Train Loss: 0.753 Vali Loss: 0.737 Vali Acc: 0.519 Test Loss: 0.737 Test Acc: 0.519\n",
      "Validation loss decreased (-0.491054 --> -0.518887).  Saving model ...\n",
      "\titers: 100, epoch: 4 | loss: 0.6528590\n",
      "\tspeed: 0.6062s/iter; left time: 14757.5538s\n",
      "\titers: 200, epoch: 4 | loss: 0.7318164\n",
      "\tspeed: 0.0199s/iter; left time: 481.6605s\n"
     ]
    }
   ],
   "source": [
    "run_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885e2a0-d1b6-4896-800c-f7989c48f453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
